{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyoLPGSX9gIJaImgBlWoAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imad-chikh/FOOD-E/blob/main/word3vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TlW5pcoofvc",
        "outputId": "6b5276f9-5a77-4a92-c122-31fb9ace1404"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ccBL-ghoZ0-",
        "outputId": "37a0afa0-f57b-4945-ee19-7973f2653700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "[('queen', 0.7118193507194519)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import gensim\n",
        "from nltk.corpus import gutenberg\n",
        "import nltk\n",
        "import gensim.downloader as api\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "# Load the dataset and prepare the sentences\n",
        "corpus = gutenberg.sents('austen-emma.txt')\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load the IMDB dataset\n",
        "num_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Preprocess the data\n",
        "max_len = 300\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBAopk92ufWp",
        "outputId": "ef5c752d-89e1-4a28-824b-6434199e951e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 300)\n",
            "(25000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "imdb_word_index = imdb.get_word_index()\n",
        "\n",
        "index_to_word = {index: word for word, index in imdb_word_index.items()}\n",
        "\n",
        "for word, index in imdb_word_index.items():\n",
        "    if index >= num_words:\n",
        "        continue\n",
        "    if word in model.key_to_index:\n",
        "        embedding_matrix[index] = model[word]\n",
        "\n",
        "\n",
        "print(embedding_matrix)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNBgXQ1IyTTl",
        "outputId": "16e7305e-98b9-4867-8efa-bdd3bf501204"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.08007812  0.10498047  0.04980469 ...  0.00366211  0.04760742\n",
            "  -0.06884766]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " ...\n",
            " [ 0.31835938 -0.08056641 -0.11816406 ... -0.21875     0.02770996\n",
            "   0.26171875]\n",
            " [ 0.13378906  0.1640625  -0.17382812 ... -0.25585938 -0.11669922\n",
            "   0.08984375]\n",
            " [-0.12353516  0.21777344 -0.578125   ...  0.12695312  0.20507812\n",
            "  -0.00543213]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dv4_nehN0mZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}